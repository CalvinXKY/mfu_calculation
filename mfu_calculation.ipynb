{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7w49/lolH8amOQppDcb6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalvinXKY/mfu_calculation/blob/main/mfu_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MFU快速计算器\n",
        "\n",
        "## 硬件配置"
      ],
      "metadata": {
        "id": "Fwy25fXe0_Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create a mfu calculation for LLM.\n",
        "\"\"\"\n",
        "# Hardware setting：\n",
        "GPU_FLOPS = 280 # 机器理论峰值 单位TFops/s\n",
        "GPU_NUMS = 1024"
      ],
      "metadata": {
        "id": "20fLIwertwv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型参数配置"
      ],
      "metadata": {
        "id": "_mxeXAW_0x0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters eg：\n",
        "GBS = 1024\n",
        "SEQ_LEN = 4096\n",
        "HIDDEN_SIZE = 1024\n",
        "NUM_HEADS = 8\n",
        "D_MODEL = 128\n",
        "VOCAB_SIZE = 32768\n",
        "NUM_QUERY_GROUPS = 4\n",
        "FFN_HIDDEN_SIZE = 2048\n",
        "LAYER_NUMS = 100\n",
        "CP = 1\n",
        "STEP_TIME = 1.5\n",
        "\n",
        "# 非MoE 模型设置top_k=0, shared_experts=1\n",
        "SHARE_EXPERTS = 1\n",
        "TOP_K = 8"
      ],
      "metadata": {
        "id": "b32Q6Vg06uqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 计算函数定义："
      ],
      "metadata": {
        "id": "FY2vkF1m4XN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 简化版：\n",
        "def mfu_calculation(step_time=STEP_TIME,\n",
        "             gbs=GBS,\n",
        "             seq_len=SEQ_LEN,\n",
        "             hidden_size=HIDDEN_SIZE,\n",
        "             vocab_size=VOCAB_SIZE,\n",
        "             num_heads=NUM_HEADS,\n",
        "             d_model=D_MODEL,\n",
        "             num_query_groups=NUM_QUERY_GROUPS,\n",
        "             ffn_hidden_size=FFN_HIDDEN_SIZE,\n",
        "             share=SHARE_EXPERTS,\n",
        "             top_k=TOP_K,\n",
        "             layer_nums=LAYER_NUMS,\n",
        "             context_parallel=CP,\n",
        "             mlp_with_gate=True):\n",
        "    embedding_flops = gbs * seq_len * hidden_size * vocab_size\n",
        "\n",
        "    # attention flops\n",
        "    q_linear = gbs * seq_len * hidden_size ** 2\n",
        "    kv_linear = gbs * seq_len * hidden_size * num_query_groups * d_model\n",
        "    kv_scores = gbs * seq_len**2 * num_heads * d_model * (context_parallel + 1) / (2 * context_parallel)\n",
        "    v_projection = gbs * seq_len**2 * num_heads * d_model * (context_parallel + 1) / (2 * context_parallel)\n",
        "\n",
        "    out_linear = gbs * seq_len * hidden_size ** 2\n",
        "    attention_layer_flops = q_linear + kv_linear + kv_scores + v_projection + out_linear\n",
        "\n",
        "    # consider layer norm. (It can be ignored)\n",
        "    layer_norm = gbs * seq_len * hidden_size\n",
        "\n",
        "    if mlp_with_gate:\n",
        "        # llama structure\n",
        "        mlp_layer_flops = 3 * gbs * seq_len * hidden_size * ffn_hidden_size\n",
        "    else:\n",
        "        mlp_layer_flops = 2 * gbs * seq_len * hidden_size * ffn_hidden_size\n",
        "\n",
        "    moe_layer_flops = mlp_layer_flops * (share + top_k)\n",
        "    model_flops = 3 * 2 * (embedding_flops + layer_nums * (attention_layer_flops + moe_layer_flops + layer_norm))\n",
        "\n",
        "    mfu = model_flops / (GPU_NUMS * step_time * (10 ** 12)) / GPU_FLOPS\n",
        "    return mfu"
      ],
      "metadata": {
        "id": "3S4AiF0eA2a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 计算测试"
      ],
      "metadata": {
        "id": "-3TSl-Qp4cQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mfu_calculation(step_time=1.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtVTqvV0TkS6",
        "outputId": "0769ec40-2dad-43e9-bf54-01a8c7872d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39771996347245714"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}